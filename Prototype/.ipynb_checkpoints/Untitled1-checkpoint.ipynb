{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from deepface import DeepFace as df\n",
    "from retinaface import RetinaFace as m\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from deepface.commons import functions\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class VideoCaptureManager:\n",
    "    def __init__(self, frame_size=(640, 480), codec='XVID'):\n",
    "        self.frame_size = frame_size\n",
    "        self.codec = codec\n",
    "        self.is_capturing = False\n",
    "        self.capture_duration = 0\n",
    "        self.frames_buffer = []  # Store frames in a temporary buffer\n",
    "\n",
    "    def start_capture(self, capture_duration):\n",
    "        self.capture_duration = capture_duration\n",
    "        self.is_capturing = True\n",
    "\n",
    "        # Open the default camera (camera index 0)\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Add the namedWindow line\n",
    "        cv2.namedWindow('Video Capture', cv2.WINDOW_NORMAL)\n",
    "\n",
    "        start_time = cv2.getTickCount()\n",
    "        while self.is_capturing:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Failed to capture video.\")\n",
    "                break\n",
    "\n",
    "            self.frames_buffer.append(frame)\n",
    "\n",
    "            # Add the namedWindow line\n",
    "            cv2.imshow('Video Capture', frame)\n",
    "\n",
    "            # Bring the window to the front\n",
    "            cv2.setWindowProperty('Video Capture', cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "            # Break the loop if 'q' key is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                self.stop_capture()\n",
    "\n",
    "            elapsed_time = (cv2.getTickCount() - start_time) / cv2.getTickFrequency()\n",
    "            if elapsed_time >= self.capture_duration:\n",
    "                self.stop_capture()\n",
    "\n",
    "        # Release resources after capturing is done\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def stop_capture(self):\n",
    "        self.is_capturing = False\n",
    "\n",
    "    def read_frames_from_buffer(self):\n",
    "        return self.frames_buffer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_manager = VideoCaptureManager()\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Press 's' to start capture, 'q' to quit: \")\n",
    "\n",
    "        if user_input == 's':\n",
    "            capture_duration = int(input(\"Enter capture duration (in seconds): \"))\n",
    "            video_manager.start_capture(capture_duration)\n",
    "        elif user_input == 'q':\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Press 's' to start capture, 'q' to quit.\")\n",
    "\n",
    "    frames_arr = video_manager.read_frames_from_buffer()\n",
    "\n",
    "    if frames_arr:\n",
    "        print(f\"Number of frames: {len(frames_arr)}\")\n",
    "    else:\n",
    "        print(\"No frames captured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bbc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = \"Data\\known_faces\"\n",
    "\n",
    "file_list = os.listdir(image_directory)\n",
    "\n",
    "paths = [os.path.join(image_directory, file) for file in file_list]\n",
    "print(paths[0])\n",
    "\n",
    "names = []\n",
    "for path in paths:\n",
    "\n",
    "    name=path.split('\\\\')\n",
    "    names.append(name[-1])\n",
    "#print()\n",
    "print(names[0])\n",
    "\n",
    "known_faces = []\n",
    "for i in range(len(names)):\n",
    "    known_faces.append([paths[i], names[i]])\n",
    "print()\n",
    "for i in range(len(known_faces)):\n",
    "    print(known_faces[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af019ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "frames.append(frames_arr[0])\n",
    "orb = cv2.ORB_create()\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "for i in range(1, len(frames_arr)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(frames[-1], None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(frames_arr[i], None)\n",
    "    \n",
    "   \n",
    "    \n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    \n",
    "    #matches = sorted(matches, key=lambda x: x.distance)\n",
    "    \n",
    "    if len(matches) < 300:\n",
    "        frames.append(frames_arr[i])\n",
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07cbb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "detected_faces = []\n",
    "count = 1\n",
    "for frame in frames[:50]:\n",
    "    obj = m.detect_faces(frame)\n",
    "    if isinstance(obj, dict):\n",
    "        for key in obj.keys():\n",
    "            faceid = obj[key]\n",
    "            area = faceid['facial_area']\n",
    "            x1,y1,x2,y2=area\n",
    "            extracted_face=frame[y1:y2,x1:x2]\n",
    "            extracted_face=cv2.cvtColor(extracted_face,cv2.COLOR_BGR2RGB)\n",
    "            detected_faces.append(extracted_face)\n",
    "print(len(detected_faces))\n",
    "plt.imshow(detected_faces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = []\n",
    "faces.append(cv2.convertScaleAbs(detected_faces[0]))\n",
    "\n",
    "for i in range(1, len(detected_faces)):\n",
    "    img2 = cv2.convertScaleAbs(detected_faces[i])\n",
    "\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(faces[-1], None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "    if descriptors2 is None:\n",
    "        \n",
    "        continue\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    if len(matches) < 100:\n",
    "        faces.append(detected_faces[i])\n",
    "\n",
    "detected_faces[:]=faces[:]\n",
    "print(len(detected_faces))\n",
    "\n",
    "plt.imshow(detected_faces[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "models=[]\n",
    "res=[]\n",
    "\n",
    "for i in range(len(detected_faces)):\n",
    "    model=df.find(img_path=detected_faces[i],db_path='Data/known_faces',model_name=\"Facenet\",distance_metric=\"euclidean\",enforce_detection=False,normalization=\"Facenet\")\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffdd90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "count = 0\n",
    "for model in models:\n",
    "    if len(model[0]) > 0:\n",
    "        print(count , \"_ \", model[0]['identity'].values[0][104:-4])\n",
    "    else:\n",
    "        print('Unknown Face detected')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9429116",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "models=[]\n",
    "res=[]\n",
    "\n",
    "for i in range(len(detected_faces)):\n",
    "    model=df.find(img_path=\"Data\\known_faces\\Ameeza\\Ameeza1.jpg\",db_path='Data/known_faces',model_name=\"Facenet\",distance_metric=\"euclidean\",enforce_detection=False,normalization=\"Facenet\")\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f6f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
